\chapter{Desarrollo específico de la contribución}\label{chap:desarrollo}

Este capítulo describe de forma detallada el desarrollo del prototipo de plataforma de observabilidad para arquitecturas de microservicios propuesto en este Trabajo Fin de Máster. Se presentan las decisiones técnicas adoptadas, el análisis de requisitos, la arquitectura del sistema, la implementación de los microservicios y la integración de las herramientas de observabilidad seleccionadas.

Asimismo, se aborda el proceso de instrumentación de los microservicios, el despliegue en un entorno orquestado mediante Kubernetes y la validación del sistema a través de pruebas funcionales y de usabilidad. El objetivo es demostrar, de manera práctica, la viabilidad y utilidad de una solución de observabilidad integrada y reproducible en entornos distribuidos.

El desarrollo descrito en este capítulo se ha llevado a cabo siguiendo la metodología definida en el Capítulo 3 y con el objetivo de cumplir los objetivos generales y específicos allí planteados. Cada una de las decisiones técnicas y fases de implementación responde directamente a los requisitos funcionales y no funcionales establecidos previamente.

El capítulo se organiza de la siguiente manera: en la Sección 4.1 se presenta la planificación del proyecto, el análisis del contexto y del problema, la justificación de las tecnologías empleadas y los requisitos funcionales y no funcionales. La Sección 4.2 describe la arquitectura del sistema y el desarrollo técnico del prototipo, incluyendo la contenerización, el despliegue y la instrumentación de los microservicios, así como la integración de las herramientas de monitorización y trazabilidad. Finalmente, la Sección 4.3 expone la evaluación del sistema mediante pruebas funcionales, el análisis de su usabilidad y aplicabilidad, y las principales limitaciones identificadas junto con posibles líneas de mejora.

\section{Planificación, Análisis y Requisitos}

Esta sección presenta el análisis previo necesario para el desarrollo del prototipo de observabilidad, abordando el contexto y el problema que motivan el proyecto, la justificación de las tecnologías seleccionadas, la organización del trabajo y la definición de los requisitos funcionales y no funcionales. Estos elementos constituyen la base sobre la cual se diseñó e implementó la solución propuesta, garantizando coherencia entre los objetivos planteados y el desarrollo técnico del sistema.

En base a los aspectos analizados, se identifican los principales retos que motivan el desarrollo del prototipo de observabilidad propuesto en este trabajo:

\begin{itemize}
	\item Contexto y problema.
	\item Justificación de tecnologías.
	\item Organización del desarrollo.
	\item Requisitos funcionales y no funcionales.
\end{itemize}

\subsection{Contexto y problema}

Las arquitecturas basadas en microservicios han ganado una adopción significativa en los últimos años debido a su capacidad para escalar de forma independiente, facilitar el despliegue continuo y permitir una mayor flexibilidad en el desarrollo de software. Sin embargo, esta descomposición de las aplicaciones en múltiples servicios autónomos introduce una complejidad operativa considerable, especialmente en lo relativo a la supervisión, el diagnóstico de errores y la comprensión del comportamiento global del sistema.

En un entorno de microservicios, cada componente se ejecuta de forma independiente, puede estar desplegado en contenedores distintos y comunicarse con otros servicios a través de la red. Como consecuencia, una única solicitud de usuario puede atravesar varios servicios antes de completarse. Identificar el origen de problemas como latencias elevadas, fallos intermitentes o degradación del rendimiento resulta complejo si no se dispone de mecanismos adecuados de observabilidad.

Uno de los principales problemas detectados en este tipo de arquitecturas es la \textbf{fragmentación de la información}. Cada microservicio genera métricas, logs y eventos de manera independiente, lo que dificulta correlacionar estos datos para obtener una visión completa del sistema. Por ejemplo, un aumento en el tiempo de respuesta percibido por el usuario puede estar provocado por un cuello de botella en un servicio intermedio, por problemas de comunicación entre servicios o por una sobrecarga puntual de recursos en un nodo del clúster.

Asimismo, la \textbf{trazabilidad de las solicitudes} representa otro desafío relevante. En ausencia de mecanismos de trazabilidad distribuida, resulta difícil seguir el recorrido de una petición a través de múltiples microservicios y determinar en qué punto se produce un retraso o un fallo. Este problema se acentúa en escenarios donde los errores no son reproducibles de forma constante o aparecen únicamente bajo determinadas condiciones de carga.

Otro aspecto crítico es la \textbf{dificultad para reproducir entornos de producción en local}. Los sistemas reales suelen ejecutarse sobre plataformas orquestadas como Kubernetes, con múltiples servicios, configuraciones dinámicas y herramientas de monitorización asociadas. Para muchos desarrolladores y equipos de operaciones, replicar este entorno con fines de prueba o aprendizaje resulta complejo y costoso, limitando la capacidad de experimentar, validar cambios o comprender el comportamiento del sistema antes de su despliegue en producción.

Además, la falta de métricas y trazas consistentes dificulta la toma de decisiones técnicas fundamentadas. Sin datos objetivos sobre consumo de recursos, latencias o tasas de error, resulta complicado optimizar el rendimiento, planificar la escalabilidad o evaluar el impacto de cambios en la arquitectura. Esto puede derivar en decisiones basadas en suposiciones, aumentando el riesgo de degradación del servicio.

Ante esta problemática, surge la necesidad de una solución de observabilidad que integre la recolección de métricas, logs y trazas, ofreciendo una visión coherente del comportamiento de los microservicios. En este contexto, el prototipo desarrollado en este trabajo busca abordar los retos identificados mediante un entorno controlado y reproducible que facilite la experimentación y evaluación de arquitecturas de microservicios.

Los principales retos que motivan el desarrollo del prototipo son:

\begin{itemize}
    \item \textbf{Visibilidad fragmentada:} los logs y métricas de cada servicio pueden encontrarse en diferentes formatos o ubicaciones, dificultando correlacionar eventos y detectar cuellos de botella.
    \item \textbf{Trazabilidad de solicitudes:} entender cómo una petición fluye a través de múltiples servicios es complejo, sobre todo cuando se presentan errores intermitentes o latencias variables.
    \item \textbf{Dificultad para pruebas locales:} replicar un entorno productivo con microservicios interconectados y sus sistemas de observabilidad requiere infraestructura y configuración que no siempre están disponibles para desarrolladores.
    \item \textbf{Necesidad de decisiones basadas en métricas:} sin métricas consistentes, es difícil evaluar el rendimiento de los servicios, optimizar recursos y tomar decisiones fundamentadas sobre mejoras o escalabilidad.
\end{itemize}

En base a estos retos, el prototipo desarrollado busca proporcionar:

\begin{itemize}
    \item Visualización centralizada del comportamiento de las aplicaciones y detección temprana de fallos.
    \item Análisis de tiempos de respuesta, latencias y carga entre servicios.
    \item Correlación de trazas de solicitudes para comprender el flujo completo entre microservicios.
    \item Entorno de aprendizaje y experimentación replicable, sin necesidad de disponer del sistema productivo completo.
\end{itemize}

Esta aproximación justifica la elección de herramientas como OpenTelemetry, Prometheus, Grafana y Jaeger, que permiten instrumentar los microservicios de manera uniforme, centralizar métricas y trazas, y ofrecer una visión coherente del sistema distribuido, resolviendo de manera práctica los problemas identificados.

\subsection{Justificación de tecnologías}

La selección de tecnologías para la plataforma de observabilidad se ha realizado considerando criterios de estandarización, facilidad de integración, soporte de la comunidad, y capacidad para cubrir los principales retos identificados en la sección anterior: visibilidad fragmentada, trazabilidad de solicitudes, dificultad para pruebas locales y necesidad de decisiones basadas en métricas.

A continuación se detallan las herramientas seleccionadas y la justificación de su inclusión:

\begin{itemize}
    \item \textbf{OpenTelemetry:} proporciona un estándar abierto para la instrumentación de aplicaciones, permitiendo recolectar métricas, trazas y logs de manera uniforme en todos los microservicios. Facilita la trazabilidad distribuida, resolviendo el reto de seguir el flujo de solicitudes a través de múltiples servicios.
    
    \item \textbf{Prometheus:} herramienta de monitorización basada en métricas, ampliamente adoptada en entornos de microservicios y Kubernetes. Permite recolectar, almacenar y consultar métricas de forma eficiente, ayudando a tomar decisiones fundamentadas sobre rendimiento y escalabilidad.
    
    \item \textbf{Grafana:} plataforma de visualización que se integra con Prometheus y otras fuentes de datos. Permite construir dashboards personalizados y visualizaciones en tiempo real, facilitando la identificación de cuellos de botella y problemas de rendimiento.
    
    \item \textbf{Jaeger:} sistema de trazabilidad distribuida que permite seguir las solicitudes a lo largo de varios microservicios. Su integración con OpenTelemetry garantiza visibilidad completa del flujo de ejecución, contribuyendo a una rápida identificación de fallos y optimización de latencias.
\end{itemize}

Para reforzar la elección de estas tecnologías, se compara brevemente con alternativas disponibles en el mercado:

\begin{table}[H]
  \centering
  \caption{Comparativa de tecnologías de observabilidad.}
  \label{tab:comparativa-tecnologias}
  \small
  \begin{tabularx}{\textwidth}{%
  >{\raggedright\arraybackslash}X
  >{\raggedright\arraybackslash}X
  >{\raggedright\arraybackslash}X
  >{\raggedright\arraybackslash}X}
  \toprule
  \textbf{Herramienta} &
  \textbf{Función} &
  \textbf{Ventajas} &
  \textbf{Limitaciones} \\
  \midrule
  OpenTelemetry &
  Instrumentación &
  Estándar abierto, integración con múltiples backends &
  Curva de aprendizaje inicial \\
  \midrule
  Prometheus &
  Métricas &
  Alta eficiencia y soporte nativo para Kubernetes &
  No centraliza logs ni trazas \\
  \midrule
  Grafana &
  Visualización &
  Dashboards flexibles y soporte multifuente &
  Necesita herramientas adicionales para trazas y logs \\
  \midrule
  Jaeger &
  Trazabilidad &
  Visualización clara de trazas distribuidas &
  Dependencia de una correcta instrumentación \\
  \bottomrule
  \end{tabularx}
  \caption*{\footnotesize Fuente: Elaboración propia.}
\end{table}  

La combinación de estas tecnologías cubre de manera integral los retos identificados:

\begin{itemize}
    \item Centraliza métricas, logs y trazas en un único ecosistema.
    \item Permite visualizar el comportamiento del sistema en tiempo real.
    \item Facilita la replicación del entorno para pruebas locales y aprendizaje.
    \item Proporciona datos objetivos para decisiones de optimización y escalabilidad.
\end{itemize}

De este modo, la plataforma propuesta garantiza una solución de observabilidad completa, reproducible y coherente con los objetivos planteados en este Trabajo Fin de Máster.

\subsection{Organización del desarrollo}

La organización del desarrollo del prototipo de plataforma de observabilidad se ha estructurado en fases claramente definidas, siguiendo un enfoque iterativo y basado en buenas prácticas de DevOps. Esta estructura permite un avance controlado, la validación temprana de resultados y la documentación sistemática de todo el proceso. 

Las fases principales del desarrollo son:

\begin{enumerate}
    \item \textbf{Planificación y análisis:} identificación del contexto y problemas, definición de objetivos, selección de herramientas y establecimiento de requisitos funcionales y no funcionales. Esta fase garantiza que el desarrollo se realice sobre una base técnica sólida y alineada con los objetivos del TFM.
    
    \item \textbf{Diseño de la arquitectura:} definición de la arquitectura de microservicios, selección de tecnologías de orquestación (Kubernetes), diseño de contenedores y planificación de la integración de herramientas de observabilidad (OpenTelemetry, Prometheus, Grafana y Jaeger). 
    
    \item \textbf{Implementación del prototipo:} desarrollo de microservicios de ejemplo con Spring Boot, instrumentación mediante OpenTelemetry, configuración de contenedores Docker, despliegue inicial en Minikube y pruebas de integración de métricas, logs y trazas.
    
    \item \textbf{Automatización y despliegue reproducible:} creación de Helm charts para la orquestación de servicios y herramientas, desarrollo de playbooks de Ansible para la configuración del entorno y definición de pipelines CI/CD con GitHub Actions. Esta fase asegura la reproducibilidad y facilita la escalabilidad del prototipo.
    
    \item \textbf{Evaluación y validación:} ejecución de pruebas funcionales y de carga, verificación de métricas y trazas, análisis de la usabilidad de los dashboards y registro de resultados. Esta fase permite identificar mejoras, cuellos de botella y oportunidades de optimización.
    
    \item \textbf{Documentación y aprendizaje:} recopilación de configuraciones, scripts, dashboards y procedimientos de despliegue, generando documentación técnica completa que pueda ser reutilizada y adaptada por otros equipos.
\end{enumerate}

La coordinación de estas fases se ha planificado de manera incremental, permitiendo:

\begin{itemize}
    \item Ajustes iterativos basados en resultados parciales y pruebas de integración.
    \item Incorporación de mejoras continuas en el prototipo y en los scripts de automatización.
    \item Verificación constante de que los objetivos técnicos y de observabilidad se cumplan.
\end{itemize}

\paragraph{Herramientas de gestión y seguimiento}

Para mantener un control riguroso del progreso, se ha utilizado:

\begin{itemize}
    \item \textbf{GitHub:} repositorio centralizado del código fuente y control de versiones de contenedores, configuraciones y scripts.
    \item \textbf{GitHub Actions:} pipelines de integración continua para automatizar compilación, pruebas y despliegue.
    \item \textbf{Tableros de planificación:} seguimiento de tareas, hitos y entregables para organizar el trabajo de manera eficiente y asegurar la trazabilidad de cada actividad.
\end{itemize}

Esta organización del desarrollo garantiza que el prototipo se construya de manera ordenada, reproducible y escalable, permitiendo una transición fluida hacia la siguiente sección, donde se describe la arquitectura del sistema y el desarrollo técnico del prototipo.

\subsection{Requisitos funcionales y no funcionales}

Para garantizar que la plataforma de observabilidad cumpla con los objetivos planteados, se han definido un conjunto de requisitos funcionales y no funcionales. Estos requisitos guían el diseño, la implementación y la evaluación del prototipo, asegurando que sea útil, reproducible y escalable.

\subsubsection{Requisitos funcionales}

Los requisitos funcionales definen las capacidades que el sistema debe ofrecer para cumplir con sus objetivos:

\begin{itemize}
    \item \textbf{RF1 - Recolección de métricas:} El sistema debe capturar métricas de rendimiento de todos los microservicios, incluyendo CPU, memoria, tiempos de respuesta y tasas de error.
    \item \textbf{RF2 - Centralización de logs:} Todos los logs generados por los microservicios deben almacenarse de manera centralizada para permitir su búsqueda, filtrado y análisis.
    \item \textbf{RF3 - Trazabilidad distribuida:} Cada solicitud que atraviese múltiples microservicios debe poder seguirse mediante trazas, identificando la duración y los puntos críticos de cada paso.
    \item \textbf{RF4 - Visualización de dashboards:} El sistema debe proporcionar dashboards interactivos que presenten métricas y trazas en tiempo real, facilitando la interpretación de los datos.
    \item \textbf{RF5 - Alertas y notificaciones:} Deben configurarse alertas automáticas ante eventos críticos, como caída de servicios, latencias excesivas o errores recurrentes.
    \item \textbf{RF6 - Despliegue reproducible:} La plataforma debe poder desplegarse de manera consistente en distintos entornos mediante automatización (Helm, Ansible, CI/CD).
\end{itemize}

\subsubsection{Requisitos no funcionales}

Los requisitos no funcionales definen las propiedades de calidad del sistema, asegurando su rendimiento, seguridad y escalabilidad:

\begin{itemize}
    \item \textbf{RNF1 - Escalabilidad:} La plataforma debe soportar un aumento en el número de microservicios sin degradar significativamente el rendimiento del monitoreo.
    \item \textbf{RNF2 - Disponibilidad:} Los componentes de observabilidad deben permanecer operativos incluso ante fallos parciales de algunos microservicios.
    \item \textbf{RNF3 - Seguridad:} Los datos recolectados deben protegerse mediante control de acceso y, cuando sea necesario, cifrado de métricas, logs y trazas.
    \item \textbf{RNF4 - Reproducibilidad:} Los despliegues deben ser consistentes y replicables en entornos locales o remotos, garantizando que los resultados obtenidos sean comparables.
    \item \textbf{RNF5 - Facilidad de mantenimiento:} La plataforma debe documentarse exhaustivamente, incluyendo configuraciones, scripts y procedimientos de despliegue.
    \item \textbf{RNF6 - Rendimiento:} La recolección y procesamiento de métricas y trazas no debe afectar significativamente el rendimiento de los microservicios.
\end{itemize}

\subsubsection{Resumen de requisitos}

Para tener una visión consolidada de los requisitos, se puede presentar la siguiente tabla:

\begin{table}[H]
  \centering
  \caption{Resumen de requisitos funcionales y no funcionales del prototipo de observabilidad.}
  \label{tab:requisitos}
  \small
  \begin{tabularx}{\textwidth}{%
  >{\raggedright\arraybackslash}l
  >{\raggedright\arraybackslash}X}
  \toprule
  \textbf{ID} &
  \textbf{Descripción} \\
  \midrule
  RF1 & Recolección de métricas de CPU, memoria, tiempos de respuesta y errores. \\
  RF2 & Centralización de logs de todos los microservicios. \\
  RF3 & Trazabilidad distribuida de solicitudes a través de microservicios. \\
  RF4 & Dashboards interactivos para métricas y trazas en tiempo real. \\
  RF5 & Alertas automáticas ante eventos críticos. \\
  RF6 & Despliegue reproducible mediante Helm, Ansible y CI/CD. \\
  RNF1 & Escalabilidad ante incremento de microservicios y datos. \\
  RNF2 & Alta disponibilidad de los componentes de observabilidad. \\
  RNF3 & Seguridad de datos mediante control de acceso y cifrado. \\
  RNF4 & Reproducibilidad de despliegues en distintos entornos. \\
  RNF5 & Facilidad de mantenimiento y documentación completa. \\
  RNF6 & Rendimiento optimizado sin afectar los microservicios. \\
  \bottomrule
  \end{tabularx}
  \caption*{\footnotesize Fuente: Elaboración propia.}
\end{table}  

\section{Descripción del sistema desarrollado e implementación}\label{sec:implementacion}

En esta sección se presenta el desarrollo concreto del prototipo de plataforma de observabilidad, incluyendo la arquitectura diseñada, la contenerización de los microservicios, la instrumentación con OpenTelemetry, el despliegue en Kubernetes y la integración de las herramientas de monitorización y trazabilidad.  

Se describen tanto los aspectos técnicos de implementación como los procedimientos seguidos para asegurar la reproducibilidad del entorno, la recolección de métricas y la visualización de trazas distribuidas. Además, se incluyen ejemplos de configuraciones YAML, capturas de dashboards y referencias a todas las figuras y tablas correspondientes.  

Los subapartados 4.2.1 a 4.2.3 detallan de manera progresiva:

\begin{itemize}
	\item 4.2.1 Arquitectura y diseño: descripción de los microservicios y componentes de observabilidad.
	\item 4.2.2 Implementación detallada: contenerización, despliegue, instrumentación y configuración de Prometheus, Grafana y Jaeger.
	\item 4.2.3 Metodología de desarrollo: enfoque iterativo, control de versiones, documentación progresiva y perspectivas de automatización con CI/CD y herramientas DevOps.
\end{itemize}

\subsection{Arquitectura y diseño}

El prototipo integra tres microservicios desarrollados con Spring Boot, instrumentados con OpenTelemetry y con exposición de métricas compatibles con Prometheus. La arquitectura fue diseñada para simular un flujo real de comunicación entre servicios y evaluar capacidades de observabilidad distribuida. En concreto, contempla:

\begin{itemize}
    \item Tres microservicios REST independientes, denominados Service-A, Service-B y Service-C, que implementan un flujo de llamadas encadenadas A → B → C.
    \item Service-A expone un endpoint de entrada que inicia la cadena de peticiones hacia Service-B, el cual a su vez invoca a Service-C, permitiendo generar trazas distribuidas completas.
    \item Prometheus como sistema de recolección de métricas, configurado para consultar periódicamente los endpoints de métricas de cada microservicio.
    \item Grafana como herramienta de visualización, conectada a Prometheus para la creación de dashboards de monitorización.
    \item Jaeger como sistema de trazabilidad distribuida, encargado de recibir y visualizar las trazas generadas durante la ejecución de las peticiones.
\end{itemize}

La Figura~\ref{fig:arquitectura} muestra la arquitectura del sistema y el flujo de comunicación entre los microservicios junto con los componentes de observabilidad.

\begin{figure}[H]
    \centering
    \caption{Arquitectura simplificada del prototipo en entorno local.}
    \includegraphics[width=0.8\textwidth]{contenido/imagenes/arquitectura-tfm.png}
    \caption*{\footnotesize Fuente: Elaboración propia.}
    \label{fig:arquitectura}
\end{figure}

\subsection{Implementación detallada}

\paragraph{Contenerización con Docker}\mbox{}

Cada microservicio fue encapsulado en una imagen Docker independiente, construida a partir de Java 17 y empaquetando la aplicación Spring Boot compilada:

\begin{verbatim}
FROM eclipse-temurin:17-jdk

COPY target/service-a-0.0.1-SNAPSHOT.jar app.jar
COPY docker/otel/opentelemetry-javaagent.jar /otel/otel.jar

ENTRYPOINT ["java","-javaagent:/otel/otel.jar","-jar","/app.jar"]
\end{verbatim}

Esta configuración permite instrumentar las peticiones HTTP, la generación de trazas y métricas básicas sin modificar el código de los microservicios.  

\paragraph{Despliegue en Kubernetes (Minikube)}\mbox{}

El despliegue se realizó sobre un clúster local con Minikube, simulando un entorno orquestado similar a producción. Cada microservicio se desplegó mediante recursos \texttt{Deployment} y \texttt{Service}, permitiendo la comunicación interna entre pods.

La instrumentación con OpenTelemetry se configuró mediante variables de entorno en los manifiestos de Kubernetes:

\begin{verbatim}
env:
- name: OTEL_SERVICE_NAME
  value: service-a
- name: OTEL_TRACES_EXPORTER
  value: otlp
- name: OTEL_EXPORTER_OTLP_ENDPOINT
  value: http://jaeger:4317
- name: OTEL_EXPORTER_OTLP_PROTOCOL
  value: grpc
- name: OTEL_METRICS_EXPORTER
  value: none
\end{verbatim}

\begin{itemize}
    \item Se define un nombre lógico para el servicio (\texttt{OTEL\_SERVICE\_NAME}).
    \item Las trazas se envían a Jaeger mediante OTLP sobre gRPC.
    \item La recolección de métricas se realiza directamente a través de Prometheus, deshabilitando la exportación de métricas del agente.
    \item Todo el proceso se realiza sin cambios en el código.
\end{itemize}

\subsubsection{Instrumentación con OpenTelemetry}

La instrumentación se realiza de forma transparente mediante el agente de OpenTelemetry integrado en Docker y configurado desde Kubernetes. Esto permite recolectar métricas, logs y trazas distribuidas sin modificar el código de los microservicios.

\subsection{Despliegue de componentes de observabilidad}

% --- Jaeger ---
\paragraph{Jaeger}
\begin{verbatim}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jaeger
spec:
  replicas: 1
  selector:
    matchLabels:
      app: jaeger
  template:
    metadata:
      labels:
        app: jaeger
    spec:
      containers:
      - name: jaeger
        image: jaegertracing/all-in-one:1.43
        ports:
        - containerPort: 16686
        - containerPort: 4317
---
apiVersion: v1
kind: Service
metadata:
  name: jaeger
spec:
  selector:
    app: jaeger
  ports:
  - port: 16686
    targetPort: 16686
  - port: 4317
    targetPort: 4317
\end{verbatim}

% --- Prometheus ---
\paragraph{Prometheus}
\begin{verbatim}
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
    scrape_configs:
      - job_name: 'microservices'
        static_configs:
          - targets: ['service-a:8080', 'service-b:8080', 'service-c:8080']
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      containers:
      - name: prometheus
        image: prom/prometheus:v2.45.0
        ports:
        - containerPort: 9090
        volumeMounts:
        - name: config
          mountPath: /etc/prometheus/
      volumes:
      - name: config
        configMap:
          name: prometheus-config
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
spec:
  selector:
    app: prometheus
  ports:
  - port: 9090
    targetPort: 9090
\end{verbatim}

% --- Grafana ---
\paragraph{Grafana}
\begin{verbatim}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
      - name: grafana
        image: grafana/grafana:10.3
        ports:
        - containerPort: 3000
---
apiVersion: v1
kind: Service
metadata:
  name: grafana
spec:
  selector:
    app: grafana
  ports:
  - port: 3000
    targetPort: 3000
\end{verbatim}

\subsection{Metodología de desarrollo y automatización}

Se siguió un enfoque iterativo, con entregas semanales que incluían desarrollo, despliegue y documentación. Esto permitió:

\begin{itemize}
    \item Validar la correcta instrumentación de los microservicios.
    \item Ajustar configuraciones y dashboards según necesidades.
    \item Documentar procedimientos de despliegue y operación del prototipo.
\end{itemize}

Este enfoque metodológico refuerza el carácter práctico del trabajo, demostrando no solo la viabilidad técnica de la plataforma de observabilidad, sino también su aplicabilidad en entornos reales de desarrollo y operación DevOps.

\section{Integración del stack de logging ELK}\label{sec:elk}

Para complementar la observabilidad mediante métricas y trazabilidad, se incorporó un sistema de logging centralizado basado en ELK Stack (Elasticsearch, Logstash/Kibana) y Filebeat. Esta solución permite recolectar, centralizar y visualizar los logs generados por cada microservicio, proporcionando una visión integral de los eventos del sistema en tiempo real.

\subsection{Arquitectura de logging}

La arquitectura implementada sigue el patrón:

\begin{itemize}
    \item \textbf{Filebeat:} Desplegado como DaemonSet en Kubernetes para recolectar los logs de todos los pods y enviarlos a Elasticsearch.
    \item \textbf{Elasticsearch:} Almacena, indexa y permite consultas eficientes sobre los logs recibidos.
    \item \textbf{Kibana:} Permite crear dashboards, búsquedas y visualizaciones de los logs centralizados.
\end{itemize}

\begin{figure}[H]
    \centering
    \caption{Arquitectura de logging centralizado con ELK y Filebeat.}
    \includegraphics[width=0.75\textwidth]{contenido/imagenes/elk-architecture.png}
    \caption*{\footnotesize Fuente: Elaboración propia.}
    \label{fig:elk-architecture}
\end{figure}

\subsection{Despliegue con Helm y Ansible}

El despliegue de ELK se realizó mediante Helm, usando los charts desarrollados para cada componente:

\begin{itemize}
    \item \texttt{elasticsearch}: Se configuró con almacenamiento persistente y replicas para garantizar disponibilidad y durabilidad de los logs.
    \item \texttt{kibana}: Se expuso mediante un servicio tipo \texttt{NodePort}, facilitando el acceso local al panel de visualización.
    \item \texttt{filebeat}: Configurado como DaemonSet para recolectar los logs de los microservicios y enviarlos a Elasticsearch.
\end{itemize}

El playbook de Ansible se encargó de inicializar Minikube, instalar Helm y aplicar los charts con los valores definidos en los \texttt{values.yaml}, asegurando que la instalación fuera reproducible y coherente en cualquier máquina local.

\subsection{Configuración de Filebeat}

Filebeat se configuró para recolectar logs de todos los microservicios desplegados en Kubernetes. A continuación se muestra un ejemplo simplificado de la sección relevante del \texttt{ConfigMap} de Filebeat:

\begin{verbatim}
filebeat.inputs:
- type: container
  paths:
    - /var/log/containers/*.log
  processors:
    - add_kubernetes_metadata:
        in_cluster: true
output.elasticsearch:
  hosts: ['elasticsearch:9200']
  username: elastic
  password: changeme
\end{verbatim}

Con esta configuración, Filebeat agrega automáticamente metadata de Kubernetes a cada log, permitiendo filtrar por nombre de pod, namespace o etiqueta del microservicio.

\subsection{Integración con microservicios}

Filebeat recolecta logs de los microservicios \texttt{service-a}, \texttt{service-b} y \texttt{service-c}, lo que permite:

\begin{itemize}
    \item Visualizar en tiempo real los logs de cada servicio individual.
    \item Filtrar y buscar eventos relevantes, como errores o excepciones.
    \item Correlacionar logs con métricas de Prometheus y trazas de Jaeger para un análisis integral.
\end{itemize}

\subsection{Ejemplo de métricas y logs recolectados}

Durante las pruebas, se registraron logs de operaciones exitosas y errores simulados. A modo de resumen, la Tabla \ref{tab:logs-microservicios} muestra la cantidad de logs recolectados por servicio y su clasificación.

\begin{table}[H]
\centering
\caption{Resumen de logs recolectados por microservicio durante la prueba.}
\begin{tabular}{lcc}
\toprule
Microservicio & Total de logs & Logs con error \\
\midrule
Service A & 200 & 5 \\
Service B & 180 & 2 \\
Service C & 190 & 0 \\
\bottomrule
\end{tabular}
\caption*{\footnotesize Fuente: Elaboración propia.}
\label{tab:logs-microservicios}
\end{table}

\subsection{Visualización y dashboards en Kibana}

Kibana se utilizó para generar dashboards que permiten:

\begin{itemize}
    \item Analizar la frecuencia de errores por microservicio.
    \item Identificar patrones o anomalías en la ejecución de los servicios.
    \item Filtrar logs por nivel de severidad, pod o timestamp.
\end{itemize}

\subsection{Discusión y buenas prácticas}

\begin{itemize}
    \item Mantener Filebeat actualizado y correctamente configurado para capturar únicamente logs relevantes, evitando sobrecarga en Elasticsearch.
    \item Definir políticas de retención y rotación de índices en Elasticsearch para optimizar el almacenamiento.
    \item Correlacionar logs con métricas de Prometheus y trazas de Jaeger para obtener una visión completa del sistema.
    \item Separar índices por microservicio o por rango temporal mejora la eficiencia de consultas y dashboards.
    \item La centralización de logs permite detectar fallos de manera rápida y facilita la identificación de cuellos de botella y errores recurrentes.
\end{itemize}

En conjunto, la integración de ELK Stack proporciona una capa de observabilidad complementaria a Prometheus y Jaeger, ofreciendo visibilidad completa sobre el comportamiento de los microservicios y el estado del sistema en entornos distribuidos.

\paragraph{Automatización con Helm y Ansible}\mbox{}

La automatización constituye un componente crítico para garantizar la reproducibilidad, consistencia y mantenimiento eficiente de la plataforma de observabilidad. Se adoptaron las siguientes prácticas:

\begin{itemize}
    \item \textbf{Helm:} Todos los recursos de Kubernetes (Deployments, Services, ConfigMaps) están empaquetados en \textit{charts} Helm. Esto permite desplegar el sistema completo mediante un solo comando, asegurando uniformidad y facilitando actualizaciones y retrocesos (\textit{rollbacks}). La estructura de Helm en el proyecto sigue la organización de los microservicios y herramientas de observabilidad, incluyendo carpetas separadas para cada componente:

\begin{verbatim}
helm/
├── microservices/
├── prometheus/
├── grafana/
└── jaeger/
\end{verbatim}

    \item \textbf{Ansible:} Se utiliza para preparar el entorno local con Minikube, instalar dependencias necesarias (Docker, kubectl, Helm) y ejecutar los despliegues de Helm de manera automatizada. La estructura de Ansible incluye un \texttt{inventory.ini} y roles con tareas específicas, por ejemplo:

\begin{verbatim}
roles/minikube/tasks/main.yml
- name: Iniciar Minikube
  command: minikube start

- name: Desplegar microservicios con Helm
  command: helm install microservices ./helm/microservices
\end{verbatim}

Esto permite ejecutar todo el despliegue desde cero con un solo comando, minimizando errores manuales y asegurando que cualquier entorno local pueda replicar la plataforma.

    \item \textbf{CI con GitHub Actions:} Se configuró un flujo de integración continua básico para construir automáticamente las imágenes Docker al detectar cambios en el repositorio:

\begin{verbatim}
name: CI TFM Observabilidad
on: [push]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Build Docker images
        run: |
          docker build -t service-a ./microservices/service-a
          docker build -t service-b ./microservices/service-b
          docker build -t service-c ./microservices/service-c
\end{verbatim}

\begin{figure}[H]
	\centering
  \caption{Arquitectura de despliegue y automatización del prototipo de observabilidad usando GitHub Actions, Docker, Ansible, Helm y Minikube.}
	\includegraphics[width=0.8\textwidth]{contenido/imagenes/flujo_ansible.png}
  \caption*{\footnotesize Fuente: Elaboración propia.}
	\label{fig:flujo-ansible}
\end{figure}

Aunque actualmente el workflow construye las imágenes, el despliegue automatizado en Minikube y la ejecución de pruebas funcionales se realiza mediante Ansible y Helm, dejando abierta la posibilidad de integrar estos pasos directamente en el pipeline CI/CD en futuras iteraciones.
\end{itemize} 

\paragraph{Beneficios de la automatización}\mbox{}

El enfoque combinado de Helm y Ansible aporta varias ventajas:

\begin{itemize}
    \item \textbf{Reproducibilidad:} cualquier entorno local puede replicar el sistema de forma idéntica.
    \item \textbf{Escalabilidad:} permite agregar nuevos microservicios o herramientas de observabilidad sin afectar la plataforma existente.
    \item \textbf{Reducción de errores humanos:} minimiza tareas manuales y repetitivas durante el despliegue.
    \item \textbf{Documentación operativa viva:} los charts y playbooks actúan como documentación de despliegue y configuración.
\end{itemize}

\paragraph{Reflexión y limitaciones}\mbox{}

El entorno local con Minikube permite experimentar y validar la instrumentación, visualización y trazabilidad. No obstante, presenta algunas limitaciones:

\begin{itemize}
    \item No refleja completamente la escalabilidad ni la tolerancia a fallos de un clúster de producción.
    \item El flujo CI/CD aún no automatiza el despliegue completo ni las pruebas funcionales directamente en GitHub Actions.
    \item Algunos recursos avanzados de Kubernetes, como volúmenes persistentes distribuidos o networking complejo, requieren adaptación adicional.
\end{itemize}

Gracias a esta metodología, el prototipo proporciona una base sólida para futuras ampliaciones, incluyendo despliegues en entornos en la nube, integración de alertas automáticas y pipelines CI/CD más completos que incluyan despliegue y pruebas automáticas.